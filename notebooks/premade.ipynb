{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Z6Wtb_jisbA"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T19:52:52.613806Z",
     "start_time": "2023-04-13T19:52:52.610815Z"
    },
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2022-12-14T04:21:08.248987Z",
     "iopub.status.busy": "2022-12-14T04:21:08.248747Z",
     "iopub.status.idle": "2022-12-14T04:21:08.252901Z",
     "shell.execute_reply": "2022-12-14T04:21:08.252380Z"
    },
    "id": "QUyRGn9riopB"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1yCdGFW4j_F"
   },
   "source": [
    "# Premade Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PS6_yKSoyLAl"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/estimator/premade\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/estimator/premade.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/estimator/premade.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/estimator/premade.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stQiPWL6ni6_"
   },
   "source": [
    "> Warning: Estimators are not recommended for new code.  Estimators run `v1.Session`-style code which is more difficult to write correctly, and can behave unexpectedly, especially when combined with TF 2 code. Estimators do fall under [compatibility guarantees](https://tensorflow.org/guide/versions), but will receive no fixes other than security vulnerabilities. See the [migration guide](https://tensorflow.org/guide/migrate) for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4YZ_ievcY7p"
   },
   "source": [
    "This tutorial shows you\n",
    "how to solve the Iris classification problem in TensorFlow using Estimators. An Estimator is a legacy TensorFlow high-level representation of a complete model. For more details see\n",
    "[Estimators](https://www.tensorflow.org/guide/estimator).\n",
    "\n",
    "Note:  In TensorFlow 2.0, the [Keras API](https://www.tensorflow.org/guide/keras) can accomplish these same tasks, and is believed to be an easier API to learn. If you are starting fresh, it is recommended you start with Keras.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "Classification is used to separate data points into classes of different labels. In this example we will use a TensorFlow estimator to classify flowers.\n",
    "\n",
    "This section is based on the following guide from [TensorFlow website](https://www.tensorflow.org/tutorials/esimator/premade)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8IFct0yedsTy"
   },
   "source": [
    "## First things first\n",
    "\n",
    "In order to get started, you will first import TensorFlow and a number of libraries you will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T19:52:53.784504Z",
     "start_time": "2023-04-13T19:52:52.614210Z"
    },
    "execution": {
     "iopub.execute_input": "2022-12-14T04:21:08.256619Z",
     "iopub.status.busy": "2022-12-14T04:21:08.256106Z",
     "iopub.status.idle": "2022-12-14T04:21:10.215144Z",
     "shell.execute_reply": "2022-12-14T04:21:10.214371Z"
    },
    "id": "jPo5bQwndr9P"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 19:53:46.580529: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5w4m5gncnGh"
   },
   "source": [
    "## The data set\n",
    "\n",
    "The sample program in this document builds and tests a model that\n",
    "classifies Iris flowers into three different species based on the size of their\n",
    "[sepals](https://en.wikipedia.org/wiki/Sepal) and\n",
    "[petals](https://en.wikipedia.org/wiki/Petal).\n",
    "\n",
    "\n",
    "You will train a model using the Iris data set. The Iris data set contains four features and one\n",
    "[label](https://developers.google.com/machine-learning/glossary/#label).\n",
    "The four features identify the following botanical characteristics of\n",
    "individual Iris flowers:\n",
    "\n",
    "* sepal length\n",
    "* sepal width\n",
    "* petal length\n",
    "* petal width\n",
    "\n",
    "Based on this information, you can define a few helpful constants for parsing the data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T19:52:53.786593Z",
     "start_time": "2023-04-13T19:52:53.784654Z"
    },
    "execution": {
     "iopub.execute_input": "2022-12-14T04:21:10.219511Z",
     "iopub.status.busy": "2022-12-14T04:21:10.219083Z",
     "iopub.status.idle": "2022-12-14T04:21:10.223057Z",
     "shell.execute_reply": "2022-12-14T04:21:10.222491Z"
    },
    "id": "lSyrXp_He_UE"
   },
   "outputs": [],
   "source": [
    "CSV_COLUMN_NAMES = [\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\", \"Species\"]\n",
    "SPECIES = [\"Setosa\", \"Versicolor\", \"Virginica\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6mTfIQzfC9w"
   },
   "source": [
    "Next, download and parse the Iris data set using Keras and Pandas. Note that you keep distinct datasets for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T19:52:53.797802Z",
     "start_time": "2023-04-13T19:52:53.788440Z"
    },
    "execution": {
     "iopub.execute_input": "2022-12-14T04:21:10.226242Z",
     "iopub.status.busy": "2022-12-14T04:21:10.225972Z",
     "iopub.status.idle": "2022-12-14T04:21:10.357818Z",
     "shell.execute_reply": "2022-12-14T04:21:10.357073Z"
    },
    "id": "PumyCN8VdGGc"
   },
   "outputs": [],
   "source": [
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "# here we use keras (a module inside of TensorFlow) to grab our datasets and read them into a pandas dataframe.\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wHFxNLszhQjz"
   },
   "source": [
    "You can inspect your data to see that you have four float feature columns and one int32 label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T19:52:53.820710Z",
     "start_time": "2023-04-13T19:52:53.802334Z"
    },
    "execution": {
     "iopub.execute_input": "2022-12-14T04:21:10.361550Z",
     "iopub.status.busy": "2022-12-14T04:21:10.361243Z",
     "iopub.status.idle": "2022-12-14T04:21:10.374329Z",
     "shell.execute_reply": "2022-12-14T04:21:10.373750Z"
    },
    "id": "WOJt-ML4hAwI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0          6.4         2.8          5.6         2.2        2\n",
       "1          5.0         2.3          3.3         1.0        1\n",
       "2          4.9         2.5          4.5         1.7        2\n",
       "3          4.9         3.1          1.5         0.1        0\n",
       "4          5.7         3.8          1.7         0.3        0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQJEYfVvfznP"
   },
   "source": [
    "For each of the datasets, split out the labels, which the model will be trained to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T19:52:53.885029Z",
     "start_time": "2023-04-13T19:52:53.812355Z"
    },
    "execution": {
     "iopub.execute_input": "2022-12-14T04:21:10.377689Z",
     "iopub.status.busy": "2022-12-14T04:21:10.377394Z",
     "iopub.status.idle": "2022-12-14T04:21:10.386858Z",
     "shell.execute_reply": "2022-12-14T04:21:10.386210Z"
    },
    "id": "zM0wz2TueuA6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
       "0          6.4         2.8          5.6         2.2\n",
       "1          5.0         2.3          3.3         1.0\n",
       "2          4.9         2.5          4.5         1.7\n",
       "3          4.9         3.1          1.5         0.1\n",
       "4          5.7         3.8          1.7         0.3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train.pop(\"Species\")\n",
    "test_y = test.pop(\"Species\")\n",
    "\n",
    "# The label column has now been removed from the features.\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZx1L_1Vcmxv"
   },
   "source": [
    "## Overview of programming with Estimators\n",
    "\n",
    "Now that you have the data set up, you can define a model using a TensorFlow Estimator. An Estimator is any class derived from `tf.estimator.Estimator`. TensorFlow provides a collection of `tf.estimator` (for example, `LinearRegressor`) to implement common ML algorithms. Beyond those, you may write your own [custom Estimators](https://www.tensorflow.org/guide/estimator#custom_estimators). It is recommended using pre-made Estimators when just getting started.\n",
    "\n",
    "To write a TensorFlow program based on pre-made Estimators, you must perform the following tasks:\n",
    "\n",
    "* Create one or more input functions.\n",
    "* Define the model's feature columns.\n",
    "* Instantiate an Estimator, specifying the feature columns and various hyperparameters.\n",
    "* Call one or more methods on the Estimator object, passing the appropriate input function as the source of the data.\n",
    "\n",
    "Let's see how those tasks are implemented for Iris classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OcguDfBcmmg"
   },
   "source": [
    "## Create input functions\n",
    "\n",
    "You must create input functions to supply data for training, evaluating, and prediction.\n",
    "\n",
    "An **input function** is a function that returns a `tf.data.Dataset` object which outputs the following two-element tuple:\n",
    "\n",
    "* [`features`](https://developers.google.com/machine-learning/glossary/#feature) - A Python dictionary in which:\n",
    "    * Each key is the name of a feature.\n",
    "    * Each value is an array containing all of that feature's values.\n",
    "* `label` - An array containing the values of the [label](https://developers.google.com/machine-learning/glossary/#label) for every example.\n",
    "\n",
    "Just to demonstrate the format of the input function, here's a simple implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T19:52:53.885119Z",
     "start_time": "2023-04-13T19:52:53.859651Z"
    },
    "execution": {
     "iopub.execute_input": "2022-12-14T04:21:10.390297Z",
     "iopub.status.busy": "2022-12-14T04:21:10.390044Z",
     "iopub.status.idle": "2022-12-14T04:21:10.394007Z",
     "shell.execute_reply": "2022-12-14T04:21:10.393412Z"
    },
    "id": "nzr5vRr5caGF"
   },
   "outputs": [],
   "source": [
    "def input_evaluation_set():\n",
    "    features = {\n",
    "        \"SepalLength\": np.array([6.4, 5.0]),\n",
    "        \"SepalWidth\":  np.array([2.8, 2.3]),\n",
    "        \"PetalLength\": np.array([5.6, 3.3]),\n",
    "        \"PetalWidth\":  np.array([2.2, 1.0]),\n",
    "    }\n",
    "    labels = np.array([2, 1])\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpXvGjfnjHgY"
   },
   "source": [
    "Your input function may generate the `features` dictionary and `label` list any\n",
    "way you like. However, It is recommended using TensorFlow's [Dataset API](https://www.tensorflow.org/guide/datasets), which can\n",
    "parse all sorts of data.\n",
    "\n",
    "The Dataset API can handle a lot of common cases for you. For example,\n",
    "using the Dataset API, you can easily read in records from a large collection\n",
    "of files in parallel and join them into a single stream.\n",
    "\n",
    "To keep things simple in this example you are going to load the data with\n",
    "[pandas](https://pandas.pydata.org/), and build an input pipeline from this\n",
    "in-memory data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T19:52:53.885151Z",
     "start_time": "2023-04-13T19:52:53.859689Z"
    },
    "execution": {
     "iopub.execute_input": "2022-12-14T04:21:10.397197Z",
     "iopub.status.busy": "2022-12-14T04:21:10.396915Z",
     "iopub.status.idle": "2022-12-14T04:21:10.401527Z",
     "shell.execute_reply": "2022-12-14T04:21:10.400820Z"
    },
    "id": "T20u1anCi8NP"
   },
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    \"\"\"An input function for training or evaluating\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle and repeat if you are in training mode.\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xIwcFT4MlZEi"
   },
   "source": [
    "## Define the feature columns\n",
    "\n",
    "A [**feature column**](https://developers.google.com/machine-learning/glossary/#feature_columns) is an object describing how the model should use raw input data from the features dictionary. When you build an Estimator model, you pass it a list of feature columns that describes each of the features you want the model to use. The `tf.feature_column` module provides many options for representing data to the model.\n",
    "\n",
    "For Iris, the 4 raw features are numeric values, so you'll build a list of feature columns to tell the Estimator model to represent each of the four features as 32-bit floating-point values. Therefore, the code to create the feature column is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T19:52:53.885183Z",
     "start_time": "2023-04-13T19:52:53.859720Z"
    },
    "execution": {
     "iopub.execute_input": "2022-12-14T04:21:10.404546Z",
     "iopub.status.busy": "2022-12-14T04:21:10.404280Z",
     "iopub.status.idle": "2022-12-14T04:21:10.408206Z",
     "shell.execute_reply": "2022-12-14T04:21:10.407494Z"
    },
    "id": "ZTTriO8FlSML"
   },
   "outputs": [],
   "source": [
    "# Feature columns describe how to use the input.\n",
    "my_feature_columns = [tf.feature_column.numeric_column(key=key) for key in train.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jpKkhMoZljco"
   },
   "source": [
    "Feature columns can be far more sophisticated than those shown here.  You can read more about Feature Columns in [this guide](https://www.tensorflow.org/guide/feature_columns).\n",
    "\n",
    "Now that you have the description of how you want the model to represent the raw features, you can build the estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuE59XHEl22K"
   },
   "source": [
    "## Instantiate an estimator\n",
    "\n",
    "The Iris problem is a classic classification problem. Fortunately, TensorFlow provides several pre-made classifier Estimators, including:\n",
    "\n",
    "* `tf.estimator.DNNClassifier` for deep models that perform multi-class classification. (Deep Neural Network)\n",
    "* `tf.estimator.DNNLinearCombinedClassifier` for wide & deep models.\n",
    "* `tf.estimator.LinearClassifier` for classifiers based on linear models.\n",
    "\n",
    "For the Iris problem, `tf.estimator.DNNClassifier` seems like the best choice. Here's how you instantiated this Estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T19:52:53.903814Z",
     "start_time": "2023-04-13T19:52:53.859750Z"
    },
    "execution": {
     "iopub.execute_input": "2022-12-14T04:21:10.411465Z",
     "iopub.status.busy": "2022-12-14T04:21:10.411206Z",
     "iopub.status.idle": "2022-12-14T04:21:13.875084Z",
     "shell.execute_reply": "2022-12-14T04:21:13.874212Z"
    },
    "id": "qnf4o2V5lcPn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpmjlis0mk\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpmjlis0mk', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 19:53:47.818737: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-13 19:53:47.819936: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers of 30 and 10 nodes respectively.\n",
    "    hidden_units=[50, 10],\n",
    "    # The model must choose between 3 classes.\n",
    "    n_classes=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzzt5nUpmEe3"
   },
   "source": [
    "## Train, Evaluate, and Predict\n",
    "\n",
    "Now that you have an Estimator object, you can call methods to do the following:\n",
    "\n",
    "* Train the model.\n",
    "* Evaluate the trained model.\n",
    "* Use the trained model to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnihuLdWmE75"
   },
   "source": [
    "### Train the model\n",
    "\n",
    "Train the model by calling the Estimator's `train` method as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T19:53:15.017659Z",
     "start_time": "2023-04-13T19:52:53.903662Z"
    },
    "execution": {
     "iopub.execute_input": "2022-12-14T04:21:13.879032Z",
     "iopub.status.busy": "2022-12-14T04:21:13.878772Z",
     "iopub.status.idle": "2022-12-14T04:21:23.636158Z",
     "shell.execute_reply": "2022-12-14T04:21:23.635490Z"
    },
    "id": "4jW08YtPl1iS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mickey/miniconda3/envs/scientificProject/lib/python3.10/site-packages/tensorflow/python/training/training_util.py:396: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/mickey/miniconda3/envs/scientificProject/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adagrad.py:93: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpmjlis0mk/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 19:53:48.282888: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-04-13 19:53:48.286929: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n",
      "2023-04-13 19:53:48.290810: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\twhile inferring type of node 'dnn/zero_fraction/cond/output/_18'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 1.5668418, step = 0\n",
      "INFO:tensorflow:global_step/sec: 269.114\n",
      "INFO:tensorflow:loss = 1.1251681, step = 100 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.59\n",
      "INFO:tensorflow:loss = 1.0393285, step = 200 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.317\n",
      "INFO:tensorflow:loss = 0.98886836, step = 300 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.182\n",
      "INFO:tensorflow:loss = 0.9471289, step = 400 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 381.531\n",
      "INFO:tensorflow:loss = 0.90569395, step = 500 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.991\n",
      "INFO:tensorflow:loss = 0.8689529, step = 600 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.087\n",
      "INFO:tensorflow:loss = 0.83629394, step = 700 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.093\n",
      "INFO:tensorflow:loss = 0.80458343, step = 800 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.344\n",
      "INFO:tensorflow:loss = 0.7831191, step = 900 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.208\n",
      "INFO:tensorflow:loss = 0.75600094, step = 1000 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.128\n",
      "INFO:tensorflow:loss = 0.7264497, step = 1100 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 619.612\n",
      "INFO:tensorflow:loss = 0.7089615, step = 1200 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.908\n",
      "INFO:tensorflow:loss = 0.68348753, step = 1300 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 528.126\n",
      "INFO:tensorflow:loss = 0.67234904, step = 1400 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.836\n",
      "INFO:tensorflow:loss = 0.6513151, step = 1500 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.953\n",
      "INFO:tensorflow:loss = 0.6404213, step = 1600 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 529.754\n",
      "INFO:tensorflow:loss = 0.6345806, step = 1700 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.181\n",
      "INFO:tensorflow:loss = 0.60642815, step = 1800 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 396.735\n",
      "INFO:tensorflow:loss = 0.59150326, step = 1900 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 388.962\n",
      "INFO:tensorflow:loss = 0.57621056, step = 2000 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.562\n",
      "INFO:tensorflow:loss = 0.57231116, step = 2100 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 406.268\n",
      "INFO:tensorflow:loss = 0.56843936, step = 2200 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.418\n",
      "INFO:tensorflow:loss = 0.55636, step = 2300 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.294\n",
      "INFO:tensorflow:loss = 0.5426597, step = 2400 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.358\n",
      "INFO:tensorflow:loss = 0.53192496, step = 2500 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 507.918\n",
      "INFO:tensorflow:loss = 0.5264604, step = 2600 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.024\n",
      "INFO:tensorflow:loss = 0.51559794, step = 2700 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.854\n",
      "INFO:tensorflow:loss = 0.5099718, step = 2800 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.236\n",
      "INFO:tensorflow:loss = 0.5046124, step = 2900 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.336\n",
      "INFO:tensorflow:loss = 0.4910198, step = 3000 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.637\n",
      "INFO:tensorflow:loss = 0.4746825, step = 3100 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 545.941\n",
      "INFO:tensorflow:loss = 0.47720885, step = 3200 (0.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.767\n",
      "INFO:tensorflow:loss = 0.47247848, step = 3300 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 527.923\n",
      "INFO:tensorflow:loss = 0.45842487, step = 3400 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 542.265\n",
      "INFO:tensorflow:loss = 0.45693484, step = 3500 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.432\n",
      "INFO:tensorflow:loss = 0.45089126, step = 3600 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 502.785\n",
      "INFO:tensorflow:loss = 0.45110095, step = 3700 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.747\n",
      "INFO:tensorflow:loss = 0.4313169, step = 3800 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.196\n",
      "INFO:tensorflow:loss = 0.4347945, step = 3900 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.146\n",
      "INFO:tensorflow:loss = 0.4391173, step = 4000 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.36\n",
      "INFO:tensorflow:loss = 0.4182834, step = 4100 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.332\n",
      "INFO:tensorflow:loss = 0.40611875, step = 4200 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 579.848\n",
      "INFO:tensorflow:loss = 0.39766392, step = 4300 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.123\n",
      "INFO:tensorflow:loss = 0.37605742, step = 4400 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.614\n",
      "INFO:tensorflow:loss = 0.37502053, step = 4500 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 582.68\n",
      "INFO:tensorflow:loss = 0.36303145, step = 4600 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.857\n",
      "INFO:tensorflow:loss = 0.36030203, step = 4700 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 589.545\n",
      "INFO:tensorflow:loss = 0.3485251, step = 4800 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.882\n",
      "INFO:tensorflow:loss = 0.34040046, step = 4900 (0.200 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmpmjlis0mk/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.33837852.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7f4a9dc8baf0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Model.\n",
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
    "    steps=5000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ybiTFDmlmes8"
   },
   "source": [
    "Note that you wrap up your `input_fn` call in a [`lambda`](https://docs.python.org/3/tutorial/controlflow.html) to capture the arguments while providing an input function that takes no arguments, as expected by the Estimator. The `steps` argument tells the method to stop training after a number of training steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNvJLH8hmsdf"
   },
   "source": [
    "### Evaluate the trained model\n",
    "\n",
    "Now that the model has been trained, you can get some statistics on its\n",
    "performance. The following code block evaluates the accuracy of the trained\n",
    "model on the test data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T19:53:15.580473Z",
     "start_time": "2023-04-13T19:53:15.018737Z"
    },
    "execution": {
     "iopub.execute_input": "2022-12-14T04:21:23.639942Z",
     "iopub.status.busy": "2022-12-14T04:21:23.639271Z",
     "iopub.status.idle": "2022-12-14T04:21:24.502482Z",
     "shell.execute_reply": "2022-12-14T04:21:24.501796Z"
    },
    "id": "A169XuO4mKxF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-13T19:54:00\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpmjlis0mk/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.37779s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-13-19:54:00\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.93333334, average_loss = 0.38742307, global_step = 5000, loss = 0.38742307\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmpmjlis0mk/model.ckpt-5000\n",
      "\n",
      "Test set accuracy: 0.933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda: input_fn(test, test_y, training=False))\n",
    "\n",
    "print(\"\\nTest set accuracy: {accuracy:0.3f}\\n\".format(**eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VnPMP5EHph17"
   },
   "source": [
    "Unlike the call to the `train` method, you did not pass the `steps` argument to evaluate. The `input_fn` for eval only yields a single [epoch](https://developers.google.com/machine-learning/glossary/#epoch) of data.\n",
    "\n",
    "The `eval_result` dictionary also contains the `average_loss` (mean loss per sample), the `loss` (mean loss per mini-batch) and the value of the estimator's `global_step` (the number of training iterations it underwent).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ur624ibpp52X"
   },
   "source": [
    "### Making predictions (inferring) from the trained model\n",
    "\n",
    "You now have a trained model that produces good evaluation results. You can now use the trained model to predict the species of an Iris flower based on some unlabeled measurements. As with training and evaluation, you make predictions using a single function call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T19:53:15.585922Z",
     "start_time": "2023-04-13T19:53:15.584346Z"
    },
    "execution": {
     "iopub.execute_input": "2022-12-14T04:21:24.506360Z",
     "iopub.status.busy": "2022-12-14T04:21:24.506075Z",
     "iopub.status.idle": "2022-12-14T04:21:24.511206Z",
     "shell.execute_reply": "2022-12-14T04:21:24.510551Z"
    },
    "id": "wltc0jpgng38"
   },
   "outputs": [],
   "source": [
    "# Generate predictions from the model\n",
    "expected = [\"Setosa\", \"Versicolor\", \"Virginica\"]\n",
    "predict_x = {\n",
    "    \"SepalLength\": [5.1, 5.9, 6.9],\n",
    "    \"SepalWidth\": [3.3, 3.0, 3.1],\n",
    "    \"PetalLength\": [1.7, 4.2, 5.4],\n",
    "    \"PetalWidth\": [0.5, 1.5, 2.1],\n",
    "}\n",
    "\n",
    "def input_fn(features, batch_size=256):\n",
    "    \"\"\"An input function for prediction.\"\"\"\n",
    "    # Convert the inputs to a Dataset without labels.\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "predictions = classifier.predict(input_fn=lambda: input_fn(predict_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JsETKQo0rHvi"
   },
   "source": [
    "The `predict` method returns a Python iterable, yielding a dictionary of prediction results for each example. The following code prints a few predictions and their probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T19:53:15.809463Z",
     "start_time": "2023-04-13T19:53:15.586033Z"
    },
    "execution": {
     "iopub.execute_input": "2022-12-14T04:21:24.514756Z",
     "iopub.status.busy": "2022-12-14T04:21:24.514188Z",
     "iopub.status.idle": "2022-12-14T04:21:24.851358Z",
     "shell.execute_reply": "2022-12-14T04:21:24.850691Z"
    },
    "id": "Efm4mLzkrCxp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpmjlis0mk/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction is \"Setosa\" (82.3%), expected \"Setosa\"\n",
      "Prediction is \"Versicolor\" (57.6%), expected \"Versicolor\"\n",
      "Prediction is \"Virginica\" (65.5%), expected \"Virginica\"\n"
     ]
    }
   ],
   "source": [
    "for pred_dict, expected in zip(predictions, expected):\n",
    "    class_id = pred_dict[\"class_ids\"][0]\n",
    "    probability = pred_dict[\"probabilities\"][class_id]\n",
    "\n",
    "    print(\"Prediction is \\\"{}\\\" ({:.1f}%), expected \\\"{}\\\"\".format(\n",
    "        SPECIES[class_id], 100 * probability, expected))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "premade.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
